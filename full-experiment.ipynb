{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.experiment\n",
    "import utils.dirtools\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config_vars\n",
    "\n",
    "experiment_name = 'impact_of_augmented_dataset_size'\n",
    "\n",
    "partition = \"validation\"\n",
    "\n",
    "total_repetitions = 10\n",
    "\n",
    "config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "\n",
    "config_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"Samples\", \"Repeat\", \"MAP\", \"Missed\", \"Merges\", \"Splits\"])\n",
    "idx = 0\n",
    "\n",
    "for max_samples in [2, 4, 6, 8, 10, 20, 40, 60, 80, 100]:\n",
    "    for repetition in range(total_repetitions):\n",
    "        print(\"Experiment\", idx, \"- max_samples:\", max_samples, \"- repetition:\", repetition)\n",
    "        \n",
    "        # Modify settings\n",
    "        config_vars[\"max_training_images\"] = max_samples\n",
    "        \n",
    "        # Reconfigure variables and data partitions\n",
    "        config_vars = utils.dirtools.setup_experiment(config_vars, experiment_name)\n",
    "        data_partitions = utils.dirtools.read_data_partitions(config_vars)\n",
    "        \n",
    "        # Run experiment\n",
    "        output = utils.experiment.run(config_vars, data_partitions, experiment_name, partition, GPU=\"2\")\n",
    "        \n",
    "        # Collect outputs\n",
    "        record = {\n",
    "            \"Samples\": max_samples,\n",
    "            \"Repeat\": repetition,\n",
    "            \"MAP\": output[\"MAP\"],\n",
    "            \"Missed\": output[\"Missed\"].sum(),\n",
    "            \"Merges\": output[\"Merges\"],\n",
    "            \"Splits\": output[\"Splits\"]\n",
    "        }\n",
    "        results.loc[idx] = record\n",
    "        idx += 1\n",
    "        \n",
    "        # Clean up directories\n",
    "        experiment_dir = config_vars[\"root_directory\"] + \"/experiments/\" + experiment_name\n",
    "        if os.path.exists(experiment_dir):\n",
    "            os.system(\"rm -Rf \" + experiment_dir)\n",
    "            \n",
    "        # Save results\n",
    "        results.to_csv(config_vars[\"root_directory\"] + \"/experiments/\" + experiment_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"/data1/image-segmentation/BBBC022/unet/experiments/impact_of_augmented_dataset_size.csv\")\n",
    "mean = results.groupby(\"Samples\").mean().reset_index()\n",
    "sem = results.groupby(\"Samples\").sem().reset_index()\n",
    "sem.columns = [c+\"_se\" for c in sem.columns]\n",
    "data = pd.concat([mean, sem], axis=1).drop([\"Samples_se\", \"Repeat\", \"Repeat_se\"], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.errorbar(x=data[\"Samples\"], y=data[\"Missed\"], yerr=data[\"Missed_se\"])\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
